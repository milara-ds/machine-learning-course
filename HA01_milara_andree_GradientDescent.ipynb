{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lnOJFqNwurSy"
   },
   "source": [
    "# Linear Regression homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ZGe_OSrurTD"
   },
   "source": [
    "The goal of this homework is to help you to understand the principles behind numerical curve fitting to the data in an actual dataset. You will complete the code left as comments in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wwU7cmWmurTQ"
   },
   "source": [
    "First import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xDrcNI_BurTb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Imua2lDburT0"
   },
   "source": [
    "We will use sklearn only to import the dataset, but otherwise the whole process will be done without sklearn (or any other automated library, for the matter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n3eLv5nyurT5"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets ## imports datasets from scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BvYGqu7purUI"
   },
   "source": [
    "The Boston Housing Dataset consists of price of houses in various places in Boston. Alongside with price, the dataset also provide information such as Crime (CRIM), areas of non-retail business in the town (INDUS), the age of people who own the house (AGE), and there are many other attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jobhJyUturUN"
   },
   "outputs": [],
   "source": [
    "boston = datasets.load_boston() ## with this we are done with sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_kqAXtsEurUd"
   },
   "source": [
    "Let's take a look at the size of the feature array:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fVgin007urUi"
   },
   "source": [
    "Next, we’ll load the data to Pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Uhsm9kRurUo"
   },
   "outputs": [],
   "source": [
    "# define the features/predictors as the pre-set feature names  \n",
    "df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "\n",
    "# Put the target (housing value -- MEDV) in another DataFrame\n",
    "target = pd.DataFrame(boston.target, columns=[\"MEDV\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D6VSeMY9urU1"
   },
   "source": [
    "We define input X and output y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uldFxlgvurU5"
   },
   "outputs": [],
   "source": [
    "X = df\n",
    "y = target['MEDV']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u64BYTdfurVE"
   },
   "source": [
    "Just check the first rows of input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "colab_type": "code",
    "id": "zt6tMG2rurVH",
    "outputId": "3eed3731-320b-4545-e5eb-2185ed7daa3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
      "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
      "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
      "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
      "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
      "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
      "\n",
      "   PTRATIO       B  LSTAT  \n",
      "0     15.3  396.90   4.98  \n",
      "1     17.8  396.90   9.14  \n",
      "2     17.8  392.83   4.03  \n",
      "3     18.7  394.63   2.94  \n",
      "4     18.7  396.90   5.33  \n",
      "0    24.0\n",
      "1    21.6\n",
      "2    34.7\n",
      "3    33.4\n",
      "4    36.2\n",
      "Name: MEDV, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(X[0:5])\n",
    "print(y[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8nsHhR5GurVP"
   },
   "source": [
    "## Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RZc8tCDUurVS"
   },
   "source": [
    "The linear prediction ${f_i}$ in a given row $X_i$ of the dataset is calculated as $X_i$ ° $\\theta^T$, where $\\theta = \\theta_0, \\theta_1, ... \\theta_n$. Now, this assumes $X_i$ has been extended with a 1 as first element, so that the 1 will multiply $\\theta_0$, which is the intercept of the linear prediction. We want the weights $\\theta$ to be such that the difference from the prediction ${f_i}$ to the actual value $y_i$ is as little as possible. Even more, we want sum of the squares of that difference to be as small as possible, for all the rows in the dataset.\n",
    "\n",
    "We call __loss__ the cummulated quadratic error in the dataset for a given $\\theta$, so we want the loss to be as small as possible, and for that we will try different values for the $\\theta$ vector, but not in a blind way, but using the __gradient descent__ optimization method.\n",
    "\n",
    "### From dataset to matrices\n",
    "First of all, we convert the dataset to regular numpy matrices so that we don't need pandas anymore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lTeDKDcYurVU",
    "outputId": "53778986-accb-465c-cb86-4fefc95a24b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n"
     ]
    }
   ],
   "source": [
    "Xnum = X.to_numpy()\n",
    "ynum = y.to_numpy()\n",
    "print(Xnum.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MRd6gaJTurVb"
   },
   "source": [
    "We put a column of ones at the left of X, as explained above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "colab_type": "code",
    "id": "buV5_rgqurVd",
    "outputId": "b05f26c6-4561-4722-a096-87c5665d966a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "ones = np.ones([X.shape[0],1])\n",
    "Xnum = np.concatenate((ones,Xnum),axis=1)\n",
    "Xnum[0:1]\n",
    "print(Xnum[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IKgMKwJKurVk"
   },
   "source": [
    "Please first define the cost function: (as a verification, the value for $\\theta =$ np.array([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]) should be a number, around 412,764)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "80EfOliaurVo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "411874.07592440146"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def quadCost(X,y,theta):\n",
    "    #sum of each computation between the row and theta vector\n",
    "    estimated = np.zeros([len(y)])\n",
    "    \n",
    "    #for to get the sum of each multiplication of row vs theta vector\n",
    "    for i in range(len(y)):\n",
    "        val = X[i] * theta \n",
    "        estimated[i] = val.sum()\n",
    "    \n",
    "    #get the difference and square the results\n",
    "    dif_sqr = (y - estimated)**2\n",
    "    \n",
    "    #compute the cost by dividing the value by 2 *len of y\n",
    "    cost = dif_sqr.sum()/(2*len(y))\n",
    "\n",
    "    return cost\n",
    "\n",
    "theta = np.ones(X.shape[1] + 1)\n",
    "quadCost(Xnum,ynum,theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r5D0dCjHurVu"
   },
   "source": [
    "Now let's define the gradient descent function, which calls quadCost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "dVN4gXkcurVx",
    "outputId": "038483d2-30eb-4c14-9003-47cff23adcff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99537116  0.89134143  0.71417917  0.93775431  0.99994412  0.99706235\n",
      "  0.9763453   0.38019994  0.97950806  0.97652251 -0.16170423  0.91458504\n",
      " -0.01862482  0.83264476]\n",
      "This is the error: 201.65406266790148\n"
     ]
    }
   ],
   "source": [
    "def graDescent(X,y,theta,iters,alpha):\n",
    "    cost = np.zeros(iters) #initialize costs with zeros\n",
    "\n",
    "    for i in range(iters):  \n",
    "        # calculate the error\n",
    "        estimated = np.zeros([len(y)])\n",
    "        for j in range(len(y)):\n",
    "            val = X[j] * theta \n",
    "            estimated[j] = val.sum() \n",
    "        \n",
    "        error = estimated - y\n",
    "\n",
    "        for j in range(len(theta)):\n",
    "            val = error * X[:,j]\n",
    "            theta[j] = theta[j] - (alpha/len(y)) * (val.sum())\n",
    "        \n",
    "        cost[i] = quadCost(Xnum,ynum,theta)\n",
    "        \n",
    "    return theta,cost\n",
    "# theta is the final updated value of theta\n",
    "# cost should be a vector of the history of costs, from the initial one\n",
    "\n",
    "theta = np.ones(X.shape[1] + 1)\n",
    "alpha = 0.000006\n",
    "iters = 250\n",
    "\n",
    "finalTheta,costVector = graDescent(Xnum,ynum,theta,iters,alpha)\n",
    "print(finalTheta)\n",
    "print(\"This is the error: {}\".format(costVector[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k9rl3aeEurV4"
   },
   "source": [
    "Initialize the values of the parameters; theta should be initialized with random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QGSQ00FBurV6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-979  577  316  732 -606  466  681  663 -683 -748 -445 -775 -471 -924]\n"
     ]
    }
   ],
   "source": [
    "# You initialization here\n",
    "theta = np.random.randint(low = -1000 , high = 1000, size = X.shape[1] + 1)\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9N5YPl_1urWC"
   },
   "source": [
    "Call gradient descent from the X, y, theta, iters and alpha, and get the final theta and the cost vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bm7VcUXlurWD"
   },
   "outputs": [],
   "source": [
    "alpha = 0.000006\n",
    "iters = 250\n",
    "\n",
    "finalTheta,costVector = graDescent(Xnum,ynum,theta,iters,alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mK_USEEfurWL"
   },
   "source": [
    "We print the value you obtained for theta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VfuZN1CcurWN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-911  342  128  503 -592  246  477  266 -444 -521    0 -625   -1 -808]\n"
     ]
    }
   ],
   "source": [
    "print(finalTheta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Oj5kWJnurWW"
   },
   "source": [
    "Graph the cost vector. If it converges, then it will be a nice curve gradually going down:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P8MaX1Y5urWZ"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 468x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# your plot code here; the figure should appear below\n",
    "\n",
    "values = np.arange(iters)\n",
    "\n",
    "plt.figure(figsize = (6.5, 5))\n",
    "plt.plot(values, costVector, )\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "LinearRegressionHomework.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
